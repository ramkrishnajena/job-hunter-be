# ğŸ§° Job Hunter Backend

> **A backend service that automatically crawls remote job listings from [RemoteOK.com](https://remoteok.com)**, stores them in a local SQLite database, and exposes REST APIs for frontend consumption â€” with scheduled crawling 4Ã— a day (or custom times like 5:13 AM).

---

## ğŸš€ Features

- ğŸ” **Playwright-based crawler** â†’ Extracts latest remote jobs from RemoteOK
- ğŸ’¾ **Prisma ORM + SQLite** â†’ Lightweight database with automatic migrations
- ğŸŒ **Express REST API** â†’ Fetch jobs, apply filters, and trigger new crawls
- â° **Node Cron Scheduler** â†’ Runs the crawler automatically (daily or multiple times a day)
- ğŸ§¹ **Normalization & Deduplication** â†’ Cleans text and avoids duplicate entries

---

## ğŸ§  Tech Stack

| Component     | Technology              |
| ------------- | ----------------------- |
| Language      | Node.js                 |
| Web Framework | Express                 |
| Crawler       | Playwright              |
| Database      | SQLite (via Prisma ORM) |
| Scheduler     | Node-Cron               |
| Environment   | dotenv                  |
| ORM Tool      | Prisma                  |

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ prisma/
â”‚ â”œâ”€â”€ schema.prisma # Prisma DB schema
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ lib/
â”‚ â”‚ â””â”€â”€ prisma.ts # Prisma client
â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”œâ”€â”€ jobs.js # Job APIs
â”‚ â”‚ â””â”€â”€ crawl.js # API endpoint to trigger crawler manually
â”‚ â””â”€â”€ server.js # Express server entry point
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ crawler.ts # Main Playwright crawler
â”‚ â””â”€â”€ scheduleCrawler.ts # Cron scheduler (runs crawler automatically)
â”‚
â”œâ”€â”€ .env # Environment variables
â”œâ”€â”€ .env.example # Environment variables name reference
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

### â° Scheduler Configuration
Crawler automatically runs **4 times per day** (every 6 hours) to keep job listings fresh and up to date.


ğŸ•“ **Schedule:**
- **00:00 (Midnight)** â€“ Initial daily crawl
- **06:00 (Morning)** â€“ Refresh job data
- **12:00 (Noon)** â€“ Mid-day update
- **18:00 (Evening)** â€“ End-of-day refresh

These times are defined in **`src/scripts/scheduleCrawler.js`** using a cron expression:

```js
cron.schedule("0 0,6,12,18 * * *", () => {
  console.log("Running scheduled crawler...");
});
```

---
## âš™ï¸ 1. Prerequisites

Before setting up, make sure you have:

- [Node.js](https://nodejs.org/) v18+
- [npm](https://www.npmjs.com/) or [yarn](https://yarnpkg.com/)
- [Playwright browsers & dependencies](https://playwright.dev/docs/cli#install-system-dependencies)

Install Playwright dependencies if not already:

```bash
npx playwright install-deps
npx playwright install
```

## ğŸš€ Quick Start (Setup Instructions)

Follow these steps **in order** ğŸ‘‡

### ğŸ§± Step 1 â€” Run Prisma Migration
Create the SQLite database and schema using Prisma:

```bash
npm run prisma:migrate
```
### Step 2 - Install Dependencies

```bash
npm install
```
### Step 3 - Setup Environment

check env names from .env.example and create your .env with your details

### Step 4 - Start the app 

To start the arr run

```bash
npm run dev
```
